---
title: "Tess_McCabe_Lab3"
author: "Tess McCabe"
date: "2/5/2018"
output:
  html_document: default
  pdf_document: default
---

$$L = Pr(a \vert \rho) \propto Exp(a \vert \rho) = \prod \rho , exp(-\rho a_i)$$

```{r, echo=TRUE}

## vector of survival times (days)
dat <- c(1,9,9,5,27,9,29,1,11,3,3,11,13,6,11,2,4,1,37,10)

## some basic exploratory analysis
hist(dat)
summary(dat)
n <- length(dat)
n


##Analytical solution
rho_mle <- 1/mean(dat)
rho_mle

## negative log-likelihood at solution
-n*log(rho_mle) + rho_mle*sum(dat) # Why not just -n*log(rho) ?

## Negative log LiKelihood function for the EXPonential model
## Version 1
lkexp <- function(rho){
  -n*log(rho) + rho*sum(dat)
}
lkexp(rho_mle) # it matches

## likelihood profile

rseq <- seq(0.01,0.4,length=200)		## range of rho values on the x-axis

## Plot in the â€“log domain:
plot(rseq,lkexp(rseq),main="Negative Log Likelihood",
	xlab="rho",ylab="-log(L)",type='l')
abline(v=rho_mle,lty=2)
abline(h=lkexp(rho_mle),lty=2)

## Plot in the linear domain
plot(rseq,exp(-lkexp(rseq)),main="Likelihood",xlab="rho",ylab="L",type='l')
abline(v=rho_mle,lty=2)

dexp(dat[1],rho_mle)
dexp(dat,rho_mle)

dexp(dat,rho_mle,log=TRUE)

## likelihood function - version 2
lkexp2 <- function(rho){
  -sum(dexp(dat,rho,log=TRUE))
}
lkexp2(rho_mle)
llk2 <- sapply(rseq,lkexp2)
llk2



plot(rseq,lkexp(rseq),main="Log Likelihood",xlab="rho",ylab="-log(L)")
lines(rseq,llk2,col=2)
abline(v=rho_mle,lty=2)
abline(h=lkexp(rho_mle),lty=2)

plot(rseq,exp(-lkexp(rseq)),main="Likelihood",xlab="rho",ylab="L")
lines(rseq,exp(-llk2),col=2)
abline(v=rho_mle,lty=2)


fit <- optimize(lkexp,lower=0.01,upper=0.5,maximum=F)
fit


fit2 <- nlm(lkexp,0.03)
fit2
```

$$ -log(L) = -n \cdot log(\rho) + \rho \sum_{i=1}^{n} a_i$$
*1) Include code to make a plot of the exponential PDF (with the MLE parameter estimate) on top of the histogram of the data.*


```{r, echo= TRUE}
hist<-hist((dat), probability= TRUE)
plot(hist)
lines(dexp(dat)*100,dat,type = "p")  # Multiplying by 100 for convienience of scale

```
**Case Sutdy 2**
Weibull distribution:

$$f(x \vert c, \lambda) = \left({{c}\over{\lambda}}\right)\left( {x \over \lambda} \right)^{c-1} exp\left( -\left( {x\over \lambda} \right)^c \right)$$
```{r, echo=TRUE}
age = 0:160
plot(age,dweibull(age,1,50),type='l',ylab="density",ylim=c(0,0.025)) 
lines(age,dweibull(age,2,50),col="red") 
lines(age,dweibull(age,.5,50),col="green") 

```
2) Does increasing the `shape` parameter cause fire risk to increase or decrease with age?

Sort of both. It shifts the age where the risk of fire is the highest later in time, but also decreases the risk of fire after that.  So a 150 year old tree will fare better in a system that matches a distribution with a "shape" parameter of 3, but a 50 year old tree is worse off than a sapling tree for that same distribution. 
```{r, echo=TRUE}
age = 0:160
plot(age,dweibull(age,1,50),type='l',ylab="density",ylim=c(0,0.025)) 
lines(age,dweibull(age,2,50),col="red") 
lines(age,dweibull(age,3,50),col="green") 

```


3) Extra Credit: Plot the CDF of these 3 distributions. What is significant about the scale parameter? What is the analytically solution for the CDF at this point? Add these lines to your CDF plot. The analytically solution for the CDF is: 

$$ F(x) = 1 - e^{(- (x/\ scale\ )^a)} $$ 
$$ 0.6 = 1 - e^{(- (x/\ 50\ )^1)}  $$ 
$$ ln(0.4) = - (x/\ 50\ )^1  $$ 
$$-0.9162907 = - (x/\ 50\ )^1 $$
$$= 45.81 $$
The scale gives the value at which certain quantiles are reached. My shape values are changing, but the graphs are intersect at one point. You can also solve the equation for an x at which the graph will be at a certain quantile. 

A plot of the CDF's:

```{r, echo=TRUE}
age = 0:160

scales<-c(50,50,50)
plot(age,pweibull(age,1,scales[1]),type='l',ylab="density") 
lines(age,pweibull(age,2,scales[2]),col="red") 
lines(age,pweibull(age,0.5,scales[3]),col="green") 
abline(h=0.60) # quantile
abline(v=45.81) #age

```




**Case study 3**

```{r, echo=TRUE}
surv = c(0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0)
n = length(surv)
y = sum(surv)
t=20 
```

$$L = Binom(y \vert N, \theta) \propto \theta^y (1-\theta)^{N-y}$$

$$L = Binom(y \vert N, \rho) \propto e^{-\rho T y} \left( 1-e^{-\rho T} \right)^{N-y}$$



*5) Please include the following in your answer:*
*- R code*
*-  Numerical estimate of rho*
*-  Negative log likelihood profile*
```{r, echo=TRUE}

surv = c(0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0)
n = length(surv)
y = sum(surv)
t=20 

exp_bionom<-function(rho){ #For t=20
  -dbinom(y,n, exp(-rho*20), log=TRUE)
}

fit_ex_binom<-optimise(exp_bionom, interval=c(0, 2))
fit_ex_binom #Estimate of Rho

### Calculating the -log likelyhood profile

plot( rseq,-dbinom(y,n, exp(-rseq*20), log=TRUE), ylab="Likelyhood", xlab="rho")
abline(v=fit_ex_binom$minimum)
```
*-  Answer the following question:  If we wanted to test the assumption that mortality rate was constant in time, which of the two data sets could we use and what model would we fit?*

We would look at the first "graduate student" data set because it captures mortality at multiple times, whereas the "adviser" data set only samples mortality at one time, meaning that the change in mortality over time is assumed. We would fit the exponential distribution, because it assumes a constant mortality rate (Chapter 2 of Clark). 



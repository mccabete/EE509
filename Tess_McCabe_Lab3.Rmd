---
title: "Tess_McCabe_Lab3"
author: "Tess McCabe"
date: "2/5/2018"
output: html_document
---

$$L = Pr(a \vert \rho) \propto Exp(a \vert \rho) = \prod \rho , exp(-\rho a_i)$$

```{r, echo=TRUE}

## vector of survival times (days)
dat <- c(1,9,9,5,27,9,29,1,11,3,3,11,13,6,11,2,4,1,37,10)

## some basic exploratory analysis
hist(dat)
summary(dat)
n <- length(dat)
n


##Analytical solution
rho_mle <- 1/mean(dat)
rho_mle

## negative log-likelihood at solution
-n*log(rho_mle) + rho_mle*sum(dat) # Why not just -n*log(rho) ?

## Negative log LiKelihood function for the EXPonential model
## Version 1
lkexp <- function(rho){
  -n*log(rho) + rho*sum(dat)
}
lkexp(rho_mle) # it matches

## likelihood profile

rseq <- seq(0.01,0.4,length=200)		## range of rho values on the x-axis

## Plot in the â€“log domain:
plot(rseq,lkexp(rseq),main="Negative Log Likelihood",
	xlab="rho",ylab="-log(L)",type='l')
abline(v=rho_mle,lty=2)
abline(h=lkexp(rho_mle),lty=2)

## Plot in the linear domain
plot(rseq,exp(-lkexp(rseq)),main="Likelihood",xlab="rho",ylab="L",type='l')
abline(v=rho_mle,lty=2)

dexp(dat[1],rho_mle)
dexp(dat,rho_mle)

dexp(dat,rho_mle,log=TRUE)

## likelihood function - version 2
lkexp2 <- function(rho){
  -sum(dexp(dat,rho,log=TRUE))
}
lkexp2(rho_mle)
llk2 <- sapply(rseq,lkexp2)
llk2



plot(rseq,lkexp(rseq),main="Log Likelihood",xlab="rho",ylab="-log(L)")
lines(rseq,llk2,col=2)
abline(v=rho_mle,lty=2)
abline(h=lkexp(rho_mle),lty=2)

plot(rseq,exp(-lkexp(rseq)),main="Likelihood",xlab="rho",ylab="L")
lines(rseq,exp(-llk2),col=2)
abline(v=rho_mle,lty=2)


fit <- optimize(lkexp,lower=0.01,upper=0.5,maximum=F)
fit


fit2 <- nlm(lkexp,0.03)
fit2
```

$$ -log(L) = -n \cdot log(\rho) + \rho \sum_{i=1}^{n} a_i$$
*1) Include code to make a plot of the exponential PDF (with the MLE parameter estimate) on top of the histogram of the data.*


```{r, echo= TRUE}
hist<-hist(dat)
plot(hist)
lines(dexp(dat),dat)

plot(dexp(dat),dat)

ggplot2::ggplot(data=dat)+
  ggplot2::geom_histogram()+
  ggplot2::geom_line()


```



**Case study 3**

```{r, echo=TRUE}
surv = c(0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0)
n = length(surv)
y = sum(surv)
t=20 
```

$$L = Binom(y \vert N, \theta) \propto \theta^y (1-\theta)^{N-y}$$

$$L = Binom(y \vert N, \rho) \propto e^{-\rho T y} \left( 1-e^{-\rho T} \right)^{N-y}$$



*5) Please include the following in your answer:*
*- R code*
*-  Numerical estimate of rho*
*-  Negative log likelihood profile*
```{r, echo=TRUE}

surv = c(0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0)
n = length(surv)
y = sum(surv)
t=20 

exp_bionom<-function(rho){ #For t=20
  -dbinom(y,n, exp(-rho*20), log=TRUE)
}

fit_ex_binom<-optimise(exp_bionom, interval=c(0, 2))
fit #Estimate of Rho

### Calculating the -log likelyhood profile

plot( rseq,-dbinom(y,n, exp(-rseq*20), log=TRUE), ylab="Likelyhood", xlab="rho")
```
*-  Answer the following question:  If we wanted to test the assumption that mortality rate was constant in time, which of the two data sets could we use and what model would we fit?*

We would look at the first "graduate student" dataset becuase it captures mortality at multiple times, whereas the "advisor" dataset only samples mortality at one time, meaning that the chage in mortality over time is assumed. 






*6) Extra Credit: A plot of the exponential PDF with two curves, one based on the Exponential model from the start of this lab and the second from the Binomial/Exponential fit you just found* 
